{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_2:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello World'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations with Constants\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Operations with Constants')\n",
    "    print(sess.run(x+y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=<unknown> dtype=int32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = tf.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = tf.multiply(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations with Placeholders\n",
      "addition 50\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Operations with Placeholders')\n",
    "    print('addition', sess.run(add, feed_dict = {x:20, y:30}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[5.,5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[2.],[2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2 = tf.constant(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_multi = tf.matmul(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(matrix_multi)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fca00f09710>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca0322a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: dict of bias values\n",
    "    '''\n",
    "    \n",
    "    #First Hidden Layer with RELU Activation\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    #Second Hidden Layer\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    #Last Output Layer\n",
    "    \n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsamp,ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost 0.1950\n",
      "Epoch: 2 cost 0.1797\n",
      "Epoch: 3 cost 0.2105\n",
      "Epoch: 4 cost 0.1661\n",
      "Epoch: 5 cost 0.1532\n",
      "Epoch: 6 cost 0.1507\n",
      "Epoch: 7 cost 0.1464\n",
      "Epoch: 8 cost 0.1297\n",
      "Epoch: 9 cost 0.1531\n",
      "Epoch: 10 cost 0.1653\n",
      "Epoch: 11 cost 0.1288\n",
      "Epoch: 12 cost 0.1848\n",
      "Epoch: 13 cost 0.1115\n",
      "Epoch: 14 cost 0.1425\n",
      "Epoch: 15 cost 0.1483\n",
      "model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _,c = sess.run([optimizer, cost], feed_dict = {x:batch_x, y:batch_y})\n",
    "        avg_cost += c/total_batch\n",
    "    \n",
    "    print(\"Epoch: {} cost {:.4f}\".format(epoch+1, avg_cost))\n",
    "\n",
    "print(\"model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_2:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print (correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96310002"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x: mnist.test.images, y: mnist.test.labels}, session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 5.9,  3. ,  5.1,  1.8]]),\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'],\n",
       "       dtype='<U10')}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as skflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    }
   ],
   "source": [
    "feature_columns = skflow.infer_real_valued_columns_from_input(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpz741kapf\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_master': '', '_tf_random_seed': None, '_model_dir': '/tmp/tmpz741kapf', '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc9e0627da0>, '_task_id': 0, '_evaluation_master': '', '_save_summary_steps': 100, '_task_type': None, '_session_config': None, '_num_worker_replicas': 0, '_keep_checkpoint_max': 5, '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "classifier = skflow.DNNClassifier(hidden_units = [10, 20, 40, 40, 20, 10], n_classes = 3, feature_columns = feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpz741kapf/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.10359, step = 1\n",
      "INFO:tensorflow:global_step/sec: 699.129\n",
      "INFO:tensorflow:loss = 0.391986, step = 101 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 921.39\n",
      "INFO:tensorflow:loss = 0.338897, step = 201 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.352\n",
      "INFO:tensorflow:loss = 0.208217, step = 301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 946.458\n",
      "INFO:tensorflow:loss = 0.131847, step = 401 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.497\n",
      "INFO:tensorflow:loss = 0.196716, step = 501 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.201\n",
      "INFO:tensorflow:loss = 0.0395968, step = 601 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.264\n",
      "INFO:tensorflow:loss = 0.00635193, step = 701 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 886.82\n",
      "INFO:tensorflow:loss = 0.0105815, step = 801 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.03\n",
      "INFO:tensorflow:loss = 0.0600931, step = 901 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 867.631\n",
      "INFO:tensorflow:loss = 0.0497395, step = 1001 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 978.756\n",
      "INFO:tensorflow:loss = 0.0241431, step = 1101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 919.354\n",
      "INFO:tensorflow:loss = 0.0121004, step = 1201 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.466\n",
      "INFO:tensorflow:loss = 0.0309295, step = 1301 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.842\n",
      "INFO:tensorflow:loss = 0.2907, step = 1401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.688\n",
      "INFO:tensorflow:loss = 0.0218287, step = 1501 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 954.561\n",
      "INFO:tensorflow:loss = 0.00199104, step = 1601 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 953.418\n",
      "INFO:tensorflow:loss = 0.00411815, step = 1701 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.893\n",
      "INFO:tensorflow:loss = 0.00347486, step = 1801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 944.363\n",
      "INFO:tensorflow:loss = 0.000715209, step = 1901 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 923.278\n",
      "INFO:tensorflow:loss = 0.00255631, step = 2001 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 953.526\n",
      "INFO:tensorflow:loss = 0.123787, step = 2101 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 925.229\n",
      "INFO:tensorflow:loss = 0.0054031, step = 2201 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 863.962\n",
      "INFO:tensorflow:loss = 0.00902514, step = 2301 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.959\n",
      "INFO:tensorflow:loss = 0.00496156, step = 2401 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.468\n",
      "INFO:tensorflow:loss = 0.00777191, step = 2501 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.069\n",
      "INFO:tensorflow:loss = 0.00353933, step = 2601 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.655\n",
      "INFO:tensorflow:loss = 0.00018039, step = 2701 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 845.37\n",
      "INFO:tensorflow:loss = 0.00228028, step = 2801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.922\n",
      "INFO:tensorflow:loss = 0.00278372, step = 2901 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.413\n",
      "INFO:tensorflow:loss = 0.000184973, step = 3001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.829\n",
      "INFO:tensorflow:loss = 0.000490086, step = 3101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.089\n",
      "INFO:tensorflow:loss = 0.000153553, step = 3201 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.147\n",
      "INFO:tensorflow:loss = 0.00014831, step = 3301 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.567\n",
      "INFO:tensorflow:loss = 0.000177066, step = 3401 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 904.926\n",
      "INFO:tensorflow:loss = 0.00150193, step = 3501 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 773.326\n",
      "INFO:tensorflow:loss = 0.000110879, step = 3601 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 874.394\n",
      "INFO:tensorflow:loss = 0.000511814, step = 3701 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 723.103\n",
      "INFO:tensorflow:loss = 0.00147537, step = 3801 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 855.35\n",
      "INFO:tensorflow:loss = 0.00113551, step = 3901 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.682\n",
      "INFO:tensorflow:loss = 5.25789e-05, step = 4001 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.738\n",
      "INFO:tensorflow:loss = 0.00157192, step = 4101 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 897.387\n",
      "INFO:tensorflow:loss = 0.000829365, step = 4201 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 897.782\n",
      "INFO:tensorflow:loss = 0.00141588, step = 4301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 744.705\n",
      "INFO:tensorflow:loss = 0.000154213, step = 4401 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 922.5\n",
      "INFO:tensorflow:loss = 0.00133461, step = 4501 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 855.01\n",
      "INFO:tensorflow:loss = 0.000756186, step = 4601 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 842.025\n",
      "INFO:tensorflow:loss = 0.00122219, step = 4701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 845.759\n",
      "INFO:tensorflow:loss = 0.000598101, step = 4801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.876\n",
      "INFO:tensorflow:loss = 3.53882e-05, step = 4901 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.713\n",
      "INFO:tensorflow:loss = 0.000150578, step = 5001 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 937.229\n",
      "INFO:tensorflow:loss = 0.000172663, step = 5101 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 896.675\n",
      "INFO:tensorflow:loss = 0.000471876, step = 5201 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 880.731\n",
      "INFO:tensorflow:loss = 0.00016594, step = 5301 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.012\n",
      "INFO:tensorflow:loss = 0.000761212, step = 5401 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 924.962\n",
      "INFO:tensorflow:loss = 4.57491e-05, step = 5501 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 1025.1\n",
      "INFO:tensorflow:loss = 4.84961e-05, step = 5601 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 978.581\n",
      "INFO:tensorflow:loss = 5.91367e-05, step = 5701 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.318\n",
      "INFO:tensorflow:loss = 0.00044701, step = 5801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 873.801\n",
      "INFO:tensorflow:loss = 2.92203e-05, step = 5901 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.315\n",
      "INFO:tensorflow:loss = 1.70205e-05, step = 6001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.501\n",
      "INFO:tensorflow:loss = 0.00040933, step = 6101 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.54\n",
      "INFO:tensorflow:loss = 0.000305229, step = 6201 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.02\n",
      "INFO:tensorflow:loss = 0.000345045, step = 6301 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.188\n",
      "INFO:tensorflow:loss = 0.00025609, step = 6401 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.427\n",
      "INFO:tensorflow:loss = 0.000260049, step = 6501 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 760.21\n",
      "INFO:tensorflow:loss = 0.000270515, step = 6601 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 985.925\n",
      "INFO:tensorflow:loss = 3.41691e-05, step = 6701 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1030.99\n",
      "INFO:tensorflow:loss = 0.000313311, step = 6801 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.662\n",
      "INFO:tensorflow:loss = 0.000248297, step = 6901 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1001.41\n",
      "INFO:tensorflow:loss = 2.38032e-05, step = 7001 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.111\n",
      "INFO:tensorflow:loss = 3.35625e-05, step = 7101 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1037.57\n",
      "INFO:tensorflow:loss = 3.03073e-05, step = 7201 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.784\n",
      "INFO:tensorflow:loss = 0.000241648, step = 7301 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 973.477\n",
      "INFO:tensorflow:loss = 0.000237018, step = 7401 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1019.51\n",
      "INFO:tensorflow:loss = 4.37388e-05, step = 7501 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.646\n",
      "INFO:tensorflow:loss = 0.000376611, step = 7601 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.337\n",
      "INFO:tensorflow:loss = 0.000402592, step = 7701 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 971.095\n",
      "INFO:tensorflow:loss = 5.74395e-05, step = 7801 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 944.81\n",
      "INFO:tensorflow:loss = 0.000235337, step = 7901 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 989.076\n",
      "INFO:tensorflow:loss = 5.07846e-05, step = 8001 (0.101 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1002.26\n",
      "INFO:tensorflow:loss = 0.000370198, step = 8101 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1002.2\n",
      "INFO:tensorflow:loss = 5.82258e-06, step = 8201 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1043.35\n",
      "INFO:tensorflow:loss = 4.77383e-05, step = 8301 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1018.55\n",
      "INFO:tensorflow:loss = 0.000326889, step = 8401 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 969.837\n",
      "INFO:tensorflow:loss = 4.70833e-05, step = 8501 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 989.381\n",
      "INFO:tensorflow:loss = 0.000193141, step = 8601 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 908.694\n",
      "INFO:tensorflow:loss = 0.000193866, step = 8701 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 871.364\n",
      "INFO:tensorflow:loss = 0.000113155, step = 8801 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 1011.21\n",
      "INFO:tensorflow:loss = 0.000150106, step = 8901 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.62\n",
      "INFO:tensorflow:loss = 1.33616e-05, step = 9001 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1049.45\n",
      "INFO:tensorflow:loss = 0.000287607, step = 9101 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.69\n",
      "INFO:tensorflow:loss = 0.000143131, step = 9201 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 975.828\n",
      "INFO:tensorflow:loss = 0.000165195, step = 9301 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.672\n",
      "INFO:tensorflow:loss = 0.000161431, step = 9401 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.704\n",
      "INFO:tensorflow:loss = 0.000131001, step = 9501 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1033.45\n",
      "INFO:tensorflow:loss = 0.000173127, step = 9601 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 985.483\n",
      "INFO:tensorflow:loss = 0.000128925, step = 9701 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.178\n",
      "INFO:tensorflow:loss = 0.000236638, step = 9801 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 873.609\n",
      "INFO:tensorflow:loss = 1.21849e-05, step = 9901 (0.114 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpz741kapf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.93105e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'gradient_clip_norm': None, 'optimizer': None, 'hidden_units': [10, 20, 40, 40, 20, 10], 'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x7fc9e15ece80>, 'embedding_lr_multipliers': None, 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float64, normalizer=None),), 'dropout': None, 'input_layer_min_slice_size': None, 'activation_fn': <function relu at 0x7fca649f2e18>})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, steps = 10000, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpz741kapf/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "iris_predictions = list(classifier.predict(X_test, as_iterable = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(iris_predictions)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      0.94      0.97        17\n",
      "          2       0.93      1.00      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, iris_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
